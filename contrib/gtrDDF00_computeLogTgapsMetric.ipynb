{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run logTgapsMetric on Multiple FBS_1.4 OpSims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook uses Multiple_Opsims.ipynb from https://github.com/RichardsGroup/LSST_OpSim/tree/master/Scripts_NBs\n",
    "as the template.\n",
    "\n",
    "Here we analyze all 75 FBS 1.4 opSims in light of the distribution of time separations, which is already an existing metric [https://sims-maf.lsst.io/_modules/lsst/sims/maf/metrics/tgaps.html#TgapsMetric](https://sims-maf.lsst.io/_modules/lsst/sims/maf/metrics/tgaps.html#TgapsMetric).  However, in this case, we look at the distribution in *log* space.  Specifically from 30s to 10 years (converted to days).  The reasoning being that characterization of AGN structure functions (or PSDs) may benefit from a relatively uniform distribution in $log \\Delta t$ space.  Rolling cadences may benefit AGNs (enabling more short time-separation observations), but extreme rolling cadences would be very bad (leaving few or no long time-separation observations).  For further discussion see the [relevant whitepaper](https://docushare.lsstcorp.org/docushare/dsweb/Get/Document-30572/richards_agn_rolling_wfd.pdf). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Important:**  \n",
    "In the next cell you need to update the `your_username` variable with **Your Username** (between the single quotes).  After you have done that, in principle, you should be able to run the notebook all at once instead of cell by cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please enter your SciServer username between the single quotes below!\n",
    "your_username = 'gtr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib to show plots inline.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the sims_maf modules needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lsst.sim.maf moduels modules\n",
    "import lsst.sims.maf.db as db\n",
    "import lsst.sims.maf.metrics as metrics\n",
    "import lsst.sims.maf.slicers as slicers\n",
    "import lsst.sims.maf.stackers as stackers\n",
    "import lsst.sims.maf.plots as plots\n",
    "import lsst.sims.maf.metricBundles as metricBundles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Important:**  \n",
    "The following code is needed before importing the `opsimUtils` module if the module is not in the same directory as the current notebook. That is, you need add the directory where the `opsimUtils` module is located to the Python search path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add opsimUtils module path to search\n",
    "import sys\n",
    "sys.path.insert(0, '../Scripts_NBs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import convenience functions\n",
    "from opsimUtils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Build connections to the OpSims databases\n",
    "The first step is to initiate opsim database objects and result database objects for the opsim databases that you want to run metrics on. Two paths are needed here:\n",
    "1. `dbDir`: The path to the OpSim database directory\n",
    "2. `outDir`: The path to the directory where you want to save the metric metadata.\n",
    "\n",
    "By providing these two paths, the function `connect_dbs()` will initiate connections and store the metadata to the designated directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if your_username == '': # do NOT put your username here, put it in the cell at the top of the notebook.\n",
    "    raise Exception('Please provide your username!  See the top of the notebook.')\n",
    "\n",
    "# Two path are needed\n",
    "dbDir = '/home/idies/workspace/lsst_cadence/FBS_1.5/' #global location of opSims\n",
    "#dbDir = '/home/idies/workspace/LSST Cadence Simulations/FBS_1.4/' #global location of opSims\n",
    "outDir = '/home/idies/workspace/Temporary/{}/scratch/MAFoutput/DDFtest/'.format(your_username) #Output for GTR metrics\n",
    "\n",
    "metricDataPath = '/home/idies/workspace/Temporary/{}/scratch/MAFoutput/DDFtest/MetricData/'.format(your_username)\n",
    "\n",
    "if not os.path.exists(os.path.abspath(outDir)):\n",
    "    os.mkdir(os.path.abspath(outDir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two dictionary are returned by the following function, \n",
    "# One (opSimDbs) is a dictionary storing all database objects\n",
    "# Another (resultDbs) is a dictionary consist of the objects directing MAF where to save metric metadata\n",
    "# Both dictionaries are indexed by OpSim run names\n",
    "opSimDbs, resultDbs = connect_dbs(dbDir, outDir)\n",
    "\n",
    "# Collect Run names to a list\n",
    "dbRuns = list(opSimDbs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['daily_ddf_v1.5_10yrs', 'agnddf_v1.5_10yrs', 'baseline_v1.5_10yrs', 'descddf_v1.5_10yrs']\n"
     ]
    }
   ],
   "source": [
    "idx = [7,46,49,52]\n",
    "dbRunsDDFtest = [dbRuns[i] for i in idx]\n",
    "print(dbRunsDDFtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `help` to get more information about the provided convenience functions, e.g., `connect_dbs()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function connect_dbs in module opsimUtils:\n",
      "\n",
      "connect_dbs(dbDir, outDir)\n",
      "    Initiate database objects to all opSim databases in the provided directory.\n",
      "    Returns a dictionary consisting all database connections and a dictionary\n",
      "    holding the resultsDb objects.\n",
      "    \n",
      "    Args:\n",
      "        dbDir(str): The path to the dabase directory.\n",
      "        outDir(str): The path to the result database directory.\n",
      "    \n",
      "    Returns:\n",
      "        opSimDbs(dict): A dictionary containing the OpsimDatabase objects for\n",
      "            opsim databases in the provided directory, keys are the run names.\n",
      "        resultDbs(str): A dictionary containing the ResultsDb objects for opsim\n",
      "            databases in the provided directory, keys are the run names.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(connect_dbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also check what OpSims are available in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dcr_nham1_ugri_v1.5_10yrs',\n",
       " 'rolling_mod6_sdf_0.20_v1.5_10yrs',\n",
       " 'wfd_depth_scale0.95_noddf_v1.5_10yrs',\n",
       " 'u60_v1.5_10yrs',\n",
       " 'footprint_stuck_rollingv1.5_10yrs',\n",
       " 'filterdist_indx4_v1.5_10yrs',\n",
       " 'wfd_depth_scale0.70_noddf_v1.5_10yrs',\n",
       " 'daily_ddf_v1.5_10yrs',\n",
       " 'alt_roll_mod2_dust_sdf_0.20_v1.5_10yrs',\n",
       " 'goodseeing_gz_v1.5_10yrs',\n",
       " 'filterdist_indx1_v1.5_10yrs',\n",
       " 'footprint_standard_goalsv1.5_10yrs',\n",
       " 'footprint_big_sky_dustv1.5_10yrs',\n",
       " 'footprint_bluer_footprintv1.5_10yrs',\n",
       " 'twilight_neo_mod4_v1.5_10yrs',\n",
       " 'goodseeing_gi_v1.5_10yrs',\n",
       " 'footprint_big_wfdv1.5_10yrs',\n",
       " 'dcr_nham2_ugr_v1.5_10yrs',\n",
       " 'short_exp_5ns_5expt_v1.5_10yrs',\n",
       " 'goodseeing_griz_v1.5_10yrs',\n",
       " 'twilight_neo_mod1_v1.5_10yrs',\n",
       " 'bulges_cadence_bulge_wfd_v1.5_10yrs',\n",
       " 'third_obs_pt120v1.5_10yrs',\n",
       " 'wfd_depth_scale0.95_v1.5_10yrs',\n",
       " 'wfd_depth_scale0.85_noddf_v1.5_10yrs',\n",
       " 'footprint_no_gp_northv1.5_10yrs',\n",
       " 'footprint_big_skyv1.5_10yrs',\n",
       " 'footprint_newBv1.5_10yrs',\n",
       " 'baseline_2snaps_v1.5_10yrs',\n",
       " 'footprint_big_sky_nouiyv1.5_10yrs',\n",
       " 'twilight_neo_mod3_v1.5_10yrs',\n",
       " 'greedy_footprint_v1.5_10yrs',\n",
       " 'wfd_depth_scale0.90_v1.5_10yrs',\n",
       " 'dcr_nham1_ug_v1.5_10yrs',\n",
       " 'rolling_mod2_sdf_0.10_v1.5_10yrs',\n",
       " 'footprint_newAv1.5_10yrs',\n",
       " 'rolling_mod3_sdf_0.10_v1.5_10yrs',\n",
       " 'var_expt_v1.5_10yrs',\n",
       " 'bulges_i_heavy_v1.5_10yrs',\n",
       " 'wfd_depth_scale0.75_v1.5_10yrs',\n",
       " 'dcr_nham2_ug_v1.5_10yrs',\n",
       " 'filterdist_indx3_v1.5_10yrs',\n",
       " 'goodseeing_i_v1.5_10yrs',\n",
       " 'short_exp_2ns_5expt_v1.5_10yrs',\n",
       " 'footprint_add_mag_cloudsv1.5_10yrs',\n",
       " 'filterdist_indx6_v1.5_10yrs',\n",
       " 'agnddf_v1.5_10yrs',\n",
       " 'wfd_depth_scale0.70_v1.5_10yrs',\n",
       " 'alt_dust_v1.5_10yrs',\n",
       " 'baseline_v1.5_10yrs',\n",
       " 'filterdist_indx7_v1.5_10yrs',\n",
       " 'wfd_depth_scale0.65_v1.5_10yrs',\n",
       " 'descddf_v1.5_10yrs',\n",
       " 'bulges_bs_v1.5_10yrs',\n",
       " 'filterdist_indx2_v1.5_10yrs',\n",
       " 'short_exp_5ns_1expt_v1.5_10yrs',\n",
       " 'wfd_depth_scale0.80_noddf_v1.5_10yrs',\n",
       " 'wfd_depth_scale0.85_v1.5_10yrs',\n",
       " 'dcr_nham2_ugri_v1.5_10yrs',\n",
       " 'third_obs_pt45v1.5_10yrs',\n",
       " 'wfd_depth_scale0.65_noddf_v1.5_10yrs',\n",
       " 'wfd_depth_scale0.80_v1.5_10yrs',\n",
       " 'bulges_cadence_i_heavy_v1.5_10yrs',\n",
       " 'filterdist_indx8_v1.5_10yrs',\n",
       " 'rolling_mod6_sdf_0.10_v1.5_10yrs',\n",
       " 'footprint_gp_smoothv1.5_10yrs',\n",
       " 'twilight_neo_mod2_v1.5_10yrs',\n",
       " 'third_obs_pt15v1.5_10yrs',\n",
       " 'bulges_bulge_wfd_v1.5_10yrs',\n",
       " 'goodseeing_gri_v1.5_10yrs',\n",
       " 'rolling_mod3_sdf_0.20_v1.5_10yrs',\n",
       " 'short_exp_2ns_1expt_v1.5_10yrs',\n",
       " 'spiders_v1.5_10yrs',\n",
       " 'third_obs_pt90v1.5_10yrs',\n",
       " 'dcr_nham1_ugr_v1.5_10yrs',\n",
       " 'wfd_depth_scale0.75_noddf_v1.5_10yrs',\n",
       " 'third_obs_pt60v1.5_10yrs',\n",
       " 'rolling_mod2_sdf_0.20_v1.5_10yrs',\n",
       " 'wfd_depth_scale0.90_noddf_v1.5_10yrs',\n",
       " 'wfd_depth_scale0.99_noddf_v1.5_10yrs',\n",
       " 'bulges_cadence_bs_v1.5_10yrs',\n",
       " 'third_obs_pt30v1.5_10yrs',\n",
       " 'wfd_depth_scale0.99_v1.5_10yrs',\n",
       " 'filterdist_indx5_v1.5_10yrs',\n",
       " 'roll_mod2_dust_sdf_0.20_v1.5_10yrs']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_opsims(dbDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daily_ddf_v1.5_10yrs\n",
      "agnddf_v1.5_10yrs\n",
      "baseline_v1.5_10yrs\n",
      "descddf_v1.5_10yrs\n"
     ]
    }
   ],
   "source": [
    "print(dbRuns[7])\n",
    "print(dbRuns[46])\n",
    "print(dbRuns[49])\n",
    "print(dbRuns[52])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define logTgapsMetric\n",
    "\n",
    "This is derived from https://sims-maf.lsst.io/lsst.sims.maf.metrics.html#module-lsst.sims.maf.metrics.tgaps\n",
    "\n",
    "This metric is almost exactly the same, but hard codes the use of *all* pairs and bins that are log distributed (from 30s to 10 yrs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From 30s to 10 years (~3e8s), converted to days, 99 bins\n",
    "bins=np.logspace(np.log10(30.0/60./60./24.),np.log10(3e8/60./60./24.),99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell defines the metric.  Note that all but one line below is meta data or bookkeeping and the one line that is the actual metric is a bit obtuse.  It might be useful to comment it in more detail (and perhaps to break it down into multiple lines that are easier to read, even if those lines are just commented out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from .baseMetric import BaseMetric\n",
    "from lsst.sims.maf.metrics import BaseMetric\n",
    "\n",
    "#__all__ = ['TgapsMetric', 'NightgapsMetric', 'NVisitsPerNightMetric']\n",
    "\n",
    "class logTgapsMetric(BaseMetric):\n",
    "    \"\"\"Histogram the log of the times of the gaps between observations.\n",
    "\n",
    "    equivalent to TgapsMetric, but with \n",
    "    allGaps=True \n",
    "    and \n",
    "    bins = np.logspace(-3.46,3.54,99) (30s to 10yrs, converted to days)\n",
    "    \n",
    "    That yields log distribution of time gaps for all pairs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    timesCol : str, opt\n",
    "        The column name for the exposure times.  Values assumed to be in days.\n",
    "        Default observationStartMJD.\n",
    "    allGaps : bool, opt\n",
    "        Histogram the gaps between all observations (True) or just successive observations (False)?\n",
    "        Default is True. If all gaps are used, this metric can become significantly slower.\n",
    "    bins : np.ndarray, opt\n",
    "        The bins to use for the histogram of time gaps (in days, or same units as timesCol).\n",
    "        Default values are log bins from 30s to 10 years.\n",
    "\n",
    "    Returns a histogram at each slice point; these histograms can be combined and plotted using the\n",
    "    'SummaryHistogram plotter'.\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, timesCol='observationStartMJD', allGaps=True, \\\n",
    "                 bins=np.logspace(np.log10(30.0/60./60./24.),np.log10(3e8/60./60./24.),99), \\\n",
    "                 units='days', **kwargs):\n",
    "        # Pass the same bins to the plotter.\n",
    "        self.bins = bins\n",
    "        self.timesCol = timesCol\n",
    "        super(logTgapsMetric, self).__init__(col=[self.timesCol], metricDtype='object', units=units, **kwargs)\n",
    "        self.allGaps = allGaps\n",
    "\n",
    "    def run(self, dataSlice, slicePoint=None):\n",
    "        if dataSlice.size < 2:\n",
    "            return self.badval\n",
    "        times = np.sort(dataSlice[self.timesCol])\n",
    "        if self.allGaps:\n",
    "            allDiffs = []\n",
    "            for i in np.arange(1,times.size,1):\n",
    "                allDiffs.append((times-np.roll(times,i))[i:])\n",
    "            dts = np.concatenate(allDiffs)\n",
    "        else:\n",
    "            dts = np.diff(times)\n",
    "        #print(dts,np.log10(dts))\n",
    "        result, bins = np.histogram(dts, self.bins)\n",
    "        #print(result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Declare metric to run on all the opSims.\n",
    "\n",
    "Currently just looking at the logTgapsMetric in the r-band, but there is no reason not to do other bands (or to look at the DDFs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metric = analysis of histogram of log time separation for observations\n",
    "metric1 = logTgapsMetric()\n",
    "\n",
    "# slicer = a grouping or subdivision of visits for the simulated survey\n",
    "# based on their position on the sky (using a Healpix grid)\n",
    "slicer1 = slicers.HealpixSlicer(nside=64)\n",
    "\n",
    "# constraint = the sql query (or 'select') that selects all visits in r band\n",
    "#constraint1 = 'filter = \"r\"'\n",
    "#constraint1 += ' and note like \"DD%\"' # added so the sky plot won't saturate (remove DDFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "#ddfFields = ['COSMOS', 'XMM-LSS', 'ELAISS1', 'ECDFS', '290']\n",
    "ddfFields = ['COSMOS', 'XMM-LSS', 'ELAISS1', 'ECDFS', 'EDFS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MetricBundle = combination of the metric, slicer, and sqlconstraint\n",
    "logTgapsBundle = metricBundles.MetricBundle(metric1, slicer1, constraint1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bundleDict = {'logTgaps': logTgapsBundle}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric1 = logTgapsMetric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healpix slicer using NSIDE=512, approximate resolution 6.870973 arcminutes\n"
     ]
    }
   ],
   "source": [
    "logtgapsMetricNameTmp = 'logtgaps_{}_{}'\n",
    "logtgapsSlicer = slicers.HealpixSlicer(nside=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmosSlicer = slicers.UserPointsSlicer(150.10833,2.233611)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set summary statistics\n",
    "summaryMetrics = [metrics.MinMetric(), metrics.MedianMetric(),\n",
    "                  metrics.MaxMetric(), metrics.RmsMetric()]\n",
    "# for metric in coaddBDict:\n",
    "#     coaddBDict[metric].setSummaryMetrics(summaryMetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runing metrics on Opsim: daily_ddf_v1.5_10yrs!\n",
      "*****************************************\n",
      "logtgaps_COSMOS_g\n",
      "logtgaps_COSMOS_r\n",
      "logtgaps_COSMOS_i\n",
      "Runing metrics on Opsim: agnddf_v1.5_10yrs!\n",
      "*****************************************\n",
      "logtgaps_COSMOS_g\n",
      "logtgaps_COSMOS_r\n",
      "logtgaps_COSMOS_i\n",
      "Runing metrics on Opsim: baseline_v1.5_10yrs!\n",
      "*****************************************\n",
      "logtgaps_COSMOS_g\n",
      "logtgaps_COSMOS_r\n",
      "logtgaps_COSMOS_i\n",
      "Runing metrics on Opsim: descddf_v1.5_10yrs!\n",
      "*****************************************\n",
      "logtgaps_COSMOS_g\n",
      "logtgaps_COSMOS_r\n",
      "logtgaps_COSMOS_i\n"
     ]
    }
   ],
   "source": [
    "# loop through opsims\n",
    "for run in dbRunsDDFtest:\n",
    "    print(f'Runing metrics on Opsim: {run}!')\n",
    "    print('*****************************************')\n",
    "    # one metric bundle dict per opsim\n",
    "    logtgapsBDict = {}\n",
    "    \n",
    "    # loop through each DDF to get proposalId\n",
    "    for ddf in ddfFields[0:1]: #[0:5]\n",
    "        propInfo = ddfInfo(opSimDbs[run], ddf)\n",
    "        \n",
    "        if propInfo is None:\n",
    "            print(f'Skip Opsim {run}!')\n",
    "            break\n",
    "        else:\n",
    "            for band in bands[1:4]: #[1:4]\n",
    "                metricName = logtgapsMetricNameTmp.format(ddf, band)\n",
    "                print(metricName)\n",
    "                #logtgapsMetric = metrics.CountMetric('observationStartMJD', metricName=metricName)\n",
    "                #logtgapsMetric = metrics.CountMetric('observationStartMJD', metricName=metricName)\n",
    "                logtgapsMetric =  logTgapsMetric(metricName=metricName)\n",
    "                logtgapsConstraint = 'filter = \"{}\"'.format(band)\n",
    "                logtgapsConstraint += ' and proposalId = {}'.format(propInfo['proposalId'])\n",
    "                logtgapsBDict[metricName] = metricBundles.MetricBundle(logtgapsMetric, \\\n",
    "                                        cosmosSlicer, logtgapsConstraint, runName=run)\n",
    "                #logtgapsBDict[metricName].setSummaryMetrics(summaryMetrics)\n",
    "\n",
    "    metricGroup = metricBundles.MetricBundleGroup(logtgapsBDict, opSimDbs[run], \\\n",
    "                                metricDataPath, resultDbs[run], verbose=False)\n",
    "    metricGroup.runAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Loop over all OpSims in dbDir and run MAF\n",
    "While constructing a metricBundleGroup from a dictionary (the cell below), you will need to provide the path to a directory (`metricDataPath` in the cell below) where you would like to store the metric data (this is **DIFFERENT** than path to the metric data, `outDir`). To construct metricbundles for plotting and further analysis, this path will be needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metricDataPath = '/home/idies/workspace/Storage/gtr/persistent/MAFOutput/MetricData/'\n",
    "#for run in dbRuns[0:3]:  #To just run the first few.\n",
    "for i,run in enumerate(dbRuns):\n",
    "    # must set run name for each opSim to store metric data into\n",
    "    # separate files\n",
    "    print(i,run) #Comment out if just running the first few\n",
    "    logTgapsBundle.setRunName(run)\n",
    "    metricGroup = metricBundles.MetricBundleGroup(bundleDict,\\\n",
    "                    opSimDbs[run], metricDataPath, resultDbs[run])\n",
    "    metricGroup.runAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this script has finished (about 5 hours), you can make plots with [plotLogTgapsMetric.ipynb](01_plotLogTgapsMetric.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
